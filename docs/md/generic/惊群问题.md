# linux-惊群问题

## 惊群问题的定义

简单的来说就是多个线程或者进程在登台同一个事件，当事件发生时候，所有线程被唤醒，但是只有一个线程获得了该事件并进行处理，其他的线程都无法获取到事件后进入等待状态。

多进程/线程的唤醒，涉及到的一个问题是上下文切换问题。频繁的上下文切换带来的一个问题是数据将频繁的在寄存器与运行队列中流转。极端情况下，时间更多的消耗在进程/线程的调度上，而不是执行

## 常见的惊群问题

在 Linux 下，我们常见的惊群效应发生于我们使用 `accept` 以及我们 `select` 、`poll` 或 `epoll` 等系统提供的 API 来处理我们的网络链接。

## 内核的解决手段

### accept处理方案

### epoll处理方案

- EPOLLEXCLUSIVE（4.5内核之后）
- SO_REUSEPORT（3.9内核之后）







# epoll惊群问题

目前有两种常见的基于epoll处理listen_fd的方式:

1. 多进程共用一个epfd来监听同一listen_fd【socket()返回的】。
2. 多进程拥有各自的epfd来监听listen_fd【socekt()返回的】。



因为listenfd是挂在epfd下面的，所以epoll下的accept还是有出现惊群的问题。



## epoll_create在fork之前创建

这种情况就是，一个epfd被所有线程使用。当有事件发生的时候，所有线程都将被唤醒。

为什么需要全部唤醒？因为内核不知道，你是否在等待文件描述符来调用 accept()函数，还是做其他事情（信号处理，定时事件）。

此种情况惊群效应已经被解决。**WQ_FLAG_EXCLUSIVE**

## epoll_create在fork之后创建

这种情况就是每个线程都单独有一个epfd。

如果我们只需要处理 accept 事件的话，貌似世界一片美好了。但是 epoll 并不是只处理 accept 事件，accept 后续的读写事件都需要处理，还有定时或者信号事件。

当连接到来时，我们需要选择一个进程来 accept，这个时候，任何一个 accept 都是可以的。当连接建立以后，后续的读写事件，却与进程有了关联。**一个请求与 a 进程建立连接后，后续的读写也应该由 a 进程来做**。

当读写事件发生时，应该通知哪个进程呢？epoll 并不知道，因此，事件有可能错误通知另一个进程，这是不对的。所以一般在每个进程（线程）里面会再次创建一个 epoll 事件循环机制，每个进程的读写事件只注册在自己进程的 epoll 中。







一种是进程级别的惊群，一种是接口级别的惊群



应该说是最后所有的惊群现象都要落到accept上。因为accpet会返回**EAGAIN**。

处理方案的话首先是accept本身的惊群问题，其次就是accept配合IO多路复用导致的问题。





网卡/协议栈边界

协议栈/socket边界





如果服务器采用accept阻塞调用方式群在2.6内核就通过增加WQ_FLAG_EXCLUSIVE在内核中就行排他解决惊群了；

只有epoll的accept才有惊群，这是因为epoll监听句柄中后续可能是accept(建连接)，也有可能是read/write网络IO事件，accept有时候一个进程处理不过来、或者accept跟读写混用进程处理，所以内核层面没直接解决epoll的惊群，交由上层应用来根据IO事件如何处理。

epoll的惊群在3.10内核加了SO_REUSEPORT来解决惊群，但如果处理accept的worker也要处理read/write（Nginx的工作方式）就可能导致不同的worker有的饥饿有的排队假死一样【因为连接事件和读写事件会一并被epoll_wait返回，这就是一个正反馈，越处理，请求越偏移过来】；

4.5的内核增加EPOLLEXCLUSIVE在内核中直接将worker放在一个大queue，同时感知worker状态来派发任务更好地解决了惊群，但是因为LIFO的机制导致在压力不大的情况下，任务主要派发给少数几个worker（能接受，压力大就会正常了）。



# 参考

[Linux内核中网络数据包的接收-第一部分 概念和框架_dog250的博客-CSDN博客](https://blog.csdn.net/dog250/article/details/50528280?ops_request_misc=%7B%22request%5Fid%22%3A%22168057572916782425139943%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=168057572916782425139943&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-50528280-null-null.article_score_rank_blog&utm_term=Linux内核中网络数据包的接收&spm=1018.2226.3001.4450)

[Linux内核中网络数据包的接收-第二部分 select/poll/epoll_dog250的博客-CSDN博客](https://blog.csdn.net/dog250/article/details/50528373)

[再谈Linux epoll惊群问题的原因和解决方案_dog250的博客-CSDN博客](https://blog.csdn.net/dog250/article/details/80837278?ops_request_misc=%7B%22request%5Fid%22%3A%22168051678916800180690179%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=168051678916800180690179&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-80837278-null-null.article_score_rank_blog&utm_term=惊群&spm=1018.2226.3001.4450)

[epoll惊群效应深度剖析 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/359774959)

[关于网络编程中惊群效应那点事儿 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/60966989)

[epoll和惊群 | plantegg](https://plantegg.github.io/2019/10/31/epoll和惊群/)